import sys
import numpy as np
import sounddevice as sd
import queue
import json
from vosk import Model, KaldiRecognizer
import os
import ollama
from piper import PiperVoice
import time

MODEL_NAME = "gemma2:2b"
voice = PiperVoice.load("models\\uk_UA-ukrainian_tts-medium.onnx")
model_path = "models\\vosk-model-small-uk-v3-small" 


SYSTEM_INSTRUCTION = (
    "–¢–∏ ‚Äî –¥–æ–±—Ä–æ–∑–∏—á–ª–∏–≤–∏–π —Ç–∞ —Ç—Ä—ñ—à–∫–∏ –∞–≥—Ä–µ—Å–∏–≤–Ω–∏–π –≥–æ–ª–æ—Å–æ–≤–∏–π –∞—Å–∏—Å—Ç–µ–Ω—Ç. "
    "–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π –∫–æ—Ä–æ—Ç–∫–æ –º–∞–∫—Å–∏–º—É–º 1 —Ä–µ—á–µ–Ω–Ω—è, –ª–∞–∫–æ–Ω—ñ—á–Ω–æ —ñ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é. –ù–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¥–æ–≤–≥–∏—Ö —Å–ø–∏—Å–∫—ñ–≤."
)

samplerate = 16000  
device_id = None    

q = queue.Queue()

def callback(indata, frames, time, status):
    if status:
        print(status, file=sys.stderr)
    q.put(bytes(indata))

def sound(txt):
    try:
        print("‚û°Ô∏è –°–∏–Ω—Ç–µ–∑...")

        audio_all = b""
        sample_rate = None

        for chunk in voice.synthesize(txt.lower()):
            if sample_rate is None:
                sample_rate = chunk.sample_rate
            audio_all += chunk.audio_int16_bytes

        print("‚û°Ô∏è –ü—Ä–æ–≥—Ä–∞–≤–∞–Ω–Ω—è...")

        audio_np = np.frombuffer(audio_all, dtype=np.int16)

        sd.play(audio_np, sample_rate)
        sd.wait()

        print("‚úîÔ∏è –ì–æ—Ç–æ–≤–æ")

    except Exception as e:
        print("–ü–æ–º–∏–ª–∫–∞ –∑–≤—É–∫—É:", e)


def ai_response(req):
    try:
        # –í–∏–∫–ª–∏–∫ –ª–æ–∫–∞–ª—å–Ω–æ—ó –º–æ–¥–µ–ª—ñ —á–µ—Ä–µ–∑ Ollama
        response = ollama.chat(model=MODEL_NAME, messages=[
            {
                'role': 'system',
                'content': SYSTEM_INSTRUCTION,
            },
            {
                'role': 'user',
                'content': req,
            },
        ])
        
        answer = response['message']['content']
        
        if "<think>" in answer:
            import re
            answer = re.sub(r'<think>.*?</think>', '', answer, flags=re.DOTALL).strip()
        # ----------------------------------

        return answer

    except Exception as e:
        print(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ Ollama: {e}")
        return "–í–∏–±–∞—á, —É –º–µ–Ω–µ —Å—Ç–∞–≤—Å—è –∑–±—ñ–π —Å–∏—Å—Ç–µ–º–∏."


print("–ó–∞–≤–∞–Ω—Ç–∞–∂—É—é –º–æ–¥–µ–ª—å (—Ü–µ –∑–∞–π–º–µ –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥)...")
try:
    model = Model(model_path)
except Exception as e:
    print(f"–ü–æ–º–∏–ª–∫–∞: –Ω–µ –∑–Ω–∞–π—à–æ–≤ –ø–∞–ø–∫—É 'model'. –ü–µ—Ä–µ–≤—ñ—Ä —à–ª—è—Ö! {e}")
    sys.exit(1)

rec = KaldiRecognizer(model, samplerate)

print("üéß –°–ª—É—Ö–∞—é... –°–∫–∞–∂–∏ —â–æ—Å—å —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é!")

try:
    with sd.RawInputStream(samplerate=samplerate, blocksize=8000, device=device_id,
                           dtype='int16', channels=1, callback=callback):
        while True:
            data = q.get()
            
            if rec.AcceptWaveform(data):
                result = json.loads(rec.Result())
                text = result.get('text', '')
                
                if text and len(text) > 1:
                    print(f"üó£Ô∏è –¢–∏ —Å–∫–∞–∑–∞–≤: {text}")
                    response = ai_response(text)

                    print(f"ü§ñ –ë–æ—Ç: {response}")
                    sound(response)

                    with q.mutex:
                        q.queue.clear()

                    rec.Reset()
                    time.sleep(0.3)
                    print("üéß –ó–Ω–æ–≤—É —Å–ª—É—Ö–∞—é...")

except KeyboardInterrupt:
    print("\n–†–æ–±–æ—Ç—É –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")